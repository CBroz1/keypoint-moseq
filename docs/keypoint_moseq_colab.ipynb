{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "preliminary-agency",
   "metadata": {},
   "source": [
    "This notebook shows how to setup a new project, train a keypoint-MoSeq model and visualize the resulting syllables. You can load keypoint tracking results from SLEAP, DeepLabCut, or using your own custom format. We provide an [example DeepLabCut dataset](https://drive.google.com/drive/folders/1UNHQ_XCQEKLPPSjGspRopWBj6-YNDV6G?usp=share_link) that can be used for the tutorial.\n",
    "\n",
    "# Colab setup\n",
    "\n",
    "- Make a copy of this notebook if you plan to make changes and want them saved\n",
    "- To use the [example data](https://drive.google.com/drive/folders/1UNHQ_XCQEKLPPSjGspRopWBj6-YNDV6G?usp=share_link), downlod it your google drive or create a shortcut to it\n",
    "- To use your own data, upload it to google drive\n",
    "- Go to \"Runtime\">\"change runtime type\" and select \"Python 3\" and \"GPU\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6660e59",
   "metadata": {},
   "source": [
    "### Install keypoint MoSeq and mount your google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3ab24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade \"jax[cuda]==0.3.22\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
    "! pip install keypoint-moseq\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a52043",
   "metadata": {},
   "source": [
    "# Project setup\n",
    "Create a new project directory with a keypoint-MoSeq `config.yml` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-kenya",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keypoint_moseq as kpms\n",
    "\n",
    "project_dir = '/content/drive/MyDrive/demo_project/'\n",
    "config = lambda: kpms.load_config(project_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890e3df1",
   "metadata": {},
   "source": [
    "### Option 1: Setup from DeepLabCut using example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aa2fcd",
   "metadata": {
    "mystnb": {
     "code_prompt_hide": "Setup from DeepLabCut",
     "code_prompt_show": "Setup from DeepLabCut"
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "dlc_config = '/content/drive/MyDrive/dlc_project/config.yaml'\n",
    "kpms.setup_project(project_dir, deeplabcut_config=dlc_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ef323f",
   "metadata": {},
   "source": [
    "### Option 2: Setup from SLEAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a6a780",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleap_file = 'XXX' # choose a .h5 file for one of your recordings\n",
    "kpms.setup_project(project_dir, sleap_file=sleap_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65bd597",
   "metadata": {},
   "source": [
    "### Options 3: Manual setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d804ac5",
   "metadata": {
    "mystnb": {
     "code_prompt_hide": "Custom setup",
     "code_prompt_show": "Custom setup"
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "bodyparts=[\n",
    "    'tail', 'spine4', 'spine3', 'spine2', 'spine1',\n",
    "    'head', 'nose', 'right ear', 'left ear']\n",
    "\n",
    "skeleton=[\n",
    "    ['tail', 'spine4'],\n",
    "    ['spine4', 'spine3'],\n",
    "    ['spine3', 'spine2'],\n",
    "    ['spine2', 'spine1'],\n",
    "    ['spine1', 'head'],\n",
    "    ['nose', 'head'],\n",
    "    ['left ear', 'head'],\n",
    "    ['right ear', 'head']]\n",
    "\n",
    "video_dir='/content/drive/MyDrive/dlc_project/videos/'\n",
    "\n",
    "kpms.setup_project(\n",
    "    project_dir,\n",
    "    video_dir=video_dir,\n",
    "    bodyparts=bodyparts,\n",
    "    skeleton=skeleton)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-viking",
   "metadata": {},
   "source": [
    "## Edit the config file\n",
    "\n",
    "The config can be edited in a text editor or using the function `kpms.update_config`, as shown below. In general, the following parameters should be specified for each project:\n",
    "\n",
    "- `bodyparts` (name of each keypoint; automatically imported from SLEAP/DeepLabCut)\n",
    "- `use_bodyparts` (subset of bodyparts to use for modeling, set to all bodyparts by default; for mice we recommend excluding the tail)\n",
    "- `anterior_bodyparts` and `posterior_bodyparts` (used for rotational alignment)\n",
    "- `video_dir` (directory with videos of each experiment)\n",
    "\n",
    "Edit the config as follows for the [example DeepLabCut dataset](https://drive.google.com/drive/folders/1UNHQ_XCQEKLPPSjGspRopWBj6-YNDV6G?usp=share_link):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-yahoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpms.update_config(\n",
    "    project_dir,\n",
    "    video_dir='/content/drive/MyDrive/dlc_project/videos/',\n",
    "    anterior_bodyparts=['nose'],\n",
    "    posterior_bodyparts=['spine4'],\n",
    "    use_bodyparts=[\n",
    "        'spine4', 'spine3', 'spine2', 'spine1',\n",
    "        'head', 'nose', 'right ear', 'left ear'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-dating",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Data can be loaded from DeepLabCut, SLEAP or from any another source as long as it has the following format, where K is the number of keypoints and D is 2 or 3\n",
    "- `coordinates`: dict from session names to keypoint coordinate arrays of shape (T,K,D). Each key should start with its video name (e.g. `coordinates[\"experiment1_etc\"]` would correspond to `experiment1.avi`. In general this will already be true if importing from SLEAP or DeepLabCut).\n",
    "    \n",
    "- `confidences`: dict from session names to **nonnegative** keypoint confidence arrays of shape (T,K). Confidences are optional (they are used to set the error prior for each observation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from DeepLabCut\n",
    "dlc_results_directory = '/content/drive/MyDrive/dlc_project/videos/'\n",
    "coordinates, confidences, bodyparts = kpms.load_deeplabcut_results(dlc_results_directory)\n",
    "\n",
    "# load data from SLEAP\n",
    "# sleap_results_directory = '...'\n",
    "# coordinates, confidences, bodyparts = kpms.load_sleap_results(sleap_results_directory)\n",
    "\n",
    "# format data for modeling\n",
    "data, labels = kpms.format_data(coordinates, confidences=confidences, **config())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-struggle",
   "metadata": {},
   "source": [
    "## Calibration [disabled in colab]\n",
    "\n",
    "The purpose of calibration is to learn the relationship between error and keypoint confidence scores. The resulting regression coefficients (`slope` and `intercept`) are used during modeling to set the noise prior on a per-frame, per-keypoint basis. **This step is disabled in colab**. In any case it can safely be skipped since the default parameters are fine for most datasets.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-theorem",
   "metadata": {},
   "source": [
    "## Fit PCA\n",
    "\n",
    "Run the cell below to fit a PCA model to aligned and centered keypoint coordinates. The model is saved to ``{project_dir}/pca.p`` and can be reloaded using ``kpms.load_pca``. Two plots are generated: a cumulative [scree plot](https://en.wikipedia.org/wiki/Scree_plot) and a depiction of each PC, where translucent nodes/edges represent the mean pose and opaque nodes/edges represent a perturbation in the direction of the PC. \n",
    "\n",
    "- After fitting, edit `latent_dimension` in the config. \n",
    "- A good heuristic is the number of dimensions needed to explain 90% of variance, or 10 dimensions - whichever is lower.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-canvas",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = kpms.fit_pca(**data, **config())\n",
    "kpms.save_pca(pca, project_dir)\n",
    "\n",
    "kpms.print_dims_to_explain_variance(pca, 0.9)\n",
    "kpms.plot_scree(pca, project_dir=project_dir)\n",
    "kpms.plot_pcs(pca, project_dir=project_dir, **config())\n",
    "\n",
    "# use the following to load an already \n",
    "# pca = kpms.load_pca(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a3a9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpms.update_config(project_dir, latent_dim=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-pantyhose",
   "metadata": {},
   "source": [
    "# Model fitting\n",
    "\n",
    "Fitting a keypoint-MoSeq model involves:\n",
    "1. **Initialization:** Auto-regressive (AR) parameters and syllable sequences are randomly initialized using pose trajectories from PCA.\n",
    "2. **Fitting an AR-HMM:** The AR parameters, transition probabilities and syllable sequences are iteratively updated through Gibbs sampling. \n",
    "3. **Fitting the full model:** All parameters, including both the AR-HMM as well as centroid, heading, noise-estimates and continuous latent states (i.e. PCA trajectories) are iteratively updated through Gibbs sampling. This step is especially useful for noisy data.\n",
    "4. **Apply the trained model:** The learned model parameters are used to infer a syllable sequence for each experiment. This step should always be applied at the end of model fitting, and it can also be used later on to infer syllable sequences for newly added data.\n",
    "\n",
    "## Setting hyperparameters\n",
    "\n",
    "There are two ways to change hyperparameters:\n",
    "1. Update the config using `kpms.update_config` and then re-initialize the model\n",
    "2. Change the model directly via `kpms.update_hypparams`\n",
    "\n",
    "In general, the main hyperparam that needs to be adjusted is **kappa**, which sets the time-scale of syllables. Higher kappa leads to longer syllables. For this tutorial we chose kappa values that yielded a median syllable duration of 400ms (12 frames). In general, you will need to tune kappa for each new dataset based on the intended syllable time-scale. **You will need to pick two kappas: one for AR-HMM fitting and one for the full model.**\n",
    "- We recommend iteratively updating kappa and refitting the model until the target syllable time-scale is attained.  \n",
    "- Model fitting can be stopped at any time by interrupting the kernel, and kappa can be adjusted as described above.\n",
    "- The full model will generally require a lower value of kappa to yield the same target syllable durations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-penetration",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-administrator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optionally update kappa in the config before initializing \n",
    "# kpms.update_config(project_dir=project_dir, kappa=NUMBER)\n",
    "\n",
    "# initialize the model\n",
    "model = kpms.init_model(data, pca=pca, **config())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-remove",
   "metadata": {},
   "source": [
    "## Fitting an AR-HMM\n",
    "\n",
    "In addition to fitting an AR-HMM, the function below:\n",
    "- generates a name for the model and a new directory in `project_dir`\n",
    "- saves a checkpoint every 10 iterations from which fitting can be restarted\n",
    "    - a single checkpoint file contains the full history of fitting, and can be used to restart fitting from any iteration\n",
    "- plots the progress of fitting every 10 iterations, including\n",
    "    - the distributions of syllable frequencies and durations for the most recent iteration\n",
    "    - the change in median syllable duration across fitting iterations\n",
    "    - the syllable sequence across iterations in a random window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888e6ff7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model, history, name = kpms.fit_model(model, data, labels, ar_only=True, \n",
    "                                      num_iters=50, project_dir=project_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-identity",
   "metadata": {},
   "source": [
    "## Fitting the full model\n",
    "\n",
    "The following code fits a full keypoint-MoSeq model, using the results of AR-HMM fitting for initialization\n",
    "- If using your own data, you may need to try a few values of kappa at this step. \n",
    "- Use `kpms.revert` to resume from the same starting point each time you restart fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-repeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model checkpoint generated during step 2 (AR-HMM fitting)\n",
    "checkpoint = kpms.load_checkpoint(project_dir=project_dir, name=name)\n",
    "\n",
    "# the following will cause fitting to resume from iteration 50, rather than the most recent iteration\n",
    "# checkpoint = kpms.revert(checkpoint, 50)\n",
    "\n",
    "# update kappa to maintain the desired syllable time-scale\n",
    "checkpoint = kpms.update_hypparams(checkpoint, kappa=9e4)\n",
    "\n",
    "model, history, name = kpms.resume_fitting(**checkpoint, project_dir=project_dir, \n",
    "                                           ar_only=False, num_iters=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-houston",
   "metadata": {},
   "source": [
    "## Extract model results\n",
    "\n",
    "Extract modeling results for each session and save the results to `{project_dir}/{name}/results.h5`. The results are stored as follows, and can be reloaded at a later time using `kpms.load_results`:\n",
    "```\n",
    "    results.h5\n",
    "    ├──session_name1\n",
    "    │  ├──estimated_coordinates  # denoised coordinates\n",
    "    │  ├──syllables_reindexed    # syllables reindexed by frequency\n",
    "    │  ├──syllables              # non-reindexed syllables labels (z)\n",
    "    │  ├──latent_state           # inferred low-dim pose state (x)\n",
    "    │  ├──centroid               # inferred centroid (v)\n",
    "    │  └──heading                # inferred heading (h)\n",
    "    ⋮\n",
    "```\n",
    "Checkout the docs for an [in-depth explanation of the modeling results](https://keypoint-moseq.readthedocs.io/en/latest/FAQs.html#interpreting-model-outputs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba915e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved model checkpoint\n",
    "checkpoint = kpms.load_checkpoint(project_dir=project_dir, name=name)\n",
    "\n",
    "# extract results\n",
    "results = kpms.extract_results(project_dir=project_dir, **config(), **checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ecaf28",
   "metadata": {},
   "source": [
    "### Save results in csv format\n",
    "\n",
    "After extracting to an h5 file, the results can optionally be saved in csv format. A separate csv file will be created for each session and saved to `{project_dir}/{name}/results/`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5551bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optionally save results as csv\n",
    "kpms.save_results_as_csv(project_dir=project_dir, name=name, **config())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ae4b70",
   "metadata": {},
   "source": [
    "## Apply to new data\n",
    "\n",
    "The code below shows how to apply a trained model to new data. This is useful if you have performed new experiments and would like to maintain an existing set of syllables. The results for the new experiments will be added to the existing `results.h5` file. **This step is optional and can be skipped if you do not have new data to add**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db35dc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved model checkpoint\n",
    "checkpoint = kpms.load_checkpoint(project_dir=project_dir, name=name)\n",
    "\n",
    "# load new data (e.g. from deeplabcut)\n",
    "new_data = 'path/to/new/data/' # can be a file, a directory, or a list of files\n",
    "coordinates, confidences = kpms.load_deeplabcut_results(new_data)\n",
    "\n",
    "results = kpms.apply_model(\n",
    "    coordinates=coordinates, \n",
    "    confidences=confidences, \n",
    "    project_dir=project_dir, \n",
    "    name=name, \n",
    "    pca=kpms.load_pca(project_dir),\n",
    "    params=checkpoint['params'],\n",
    "    hypparams=checkpoint['hypparams'],\n",
    "    **config())\n",
    "\n",
    "# optionally rerun `save_results_as_csv` to export the new results\n",
    "kpms.save_results_as_csv(project_dir=project_dir, name=name, **config())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-fashion",
   "metadata": {},
   "source": [
    "# Visualize syllables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2491a0d",
   "metadata": {},
   "source": [
    "## Trajectory plots\n",
    "Generate plots showing the average trajectory of poses associated with each given syllable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-disney",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpms.generate_trajectory_plots(coordinates=coordinates, name=name, project_dir=project_dir, **config())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617a66ed",
   "metadata": {},
   "source": [
    "## Crowd & grid movies\n",
    "Generate video clips showing examples of each syllable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-packet",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpms.generate_grid_movies(name=name, project_dir=project_dir, coordinates=coordinates, **config())\n",
    "kpms.generate_crowd_movies(name=name, project_dir=project_dir, coordinates=coordinates, **config())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keypoint_moseq",
   "language": "python",
   "name": "keypoint_moseq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
